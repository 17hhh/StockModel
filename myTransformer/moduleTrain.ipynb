{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2910315:MainThread](2024-12-09 21:46:43,637) INFO - qlib.Initialization - [config.py:420] - default_conf: client.\n",
      "[2910315:MainThread](2024-12-09 21:46:43,638) INFO - qlib.Initialization - [__init__.py:74] - qlib successfully initialized based on client settings.\n",
      "[2910315:MainThread](2024-12-09 21:46:43,639) INFO - qlib.Initialization - [__init__.py:76] - data_path={'__DEFAULT_FREQ': PosixPath('/home/hhh/.qlib/qlib_data/cn_data')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleNotFoundError. CatBoostModel are skipped. (optional: maybe installing CatBoostModel can fix it.)\n",
      "ModuleNotFoundError. XGBModel is skipped(optional: maybe installing xgboost can fix it).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hhh/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[2910315:MainThread](2024-12-09 21:46:57,923) INFO - qlib.timer - [log.py:127] - Time cost: 12.983s | Loading data Done\n",
      "/home/hhh/.local/lib/python3.11/site-packages/numpy/lib/nanfunctions.py:1095: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanmedian1d, axis, a, overwrite_input)\n",
      "[2910315:MainThread](2024-12-09 21:47:01,660) INFO - qlib.timer - [log.py:127] - Time cost: 3.554s | RobustZScoreNorm Done\n",
      "[2910315:MainThread](2024-12-09 21:47:01,788) INFO - qlib.timer - [log.py:127] - Time cost: 0.127s | Fillna Done\n",
      "[2910315:MainThread](2024-12-09 21:47:01,862) INFO - qlib.timer - [log.py:127] - Time cost: 0.048s | DropnaLabel Done\n",
      "/home/hhh/miniconda3/envs/myModule/lib/python3.11/site-packages/qlib/data/dataset/processor.py:363: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[cols] = t\n",
      "[2910315:MainThread](2024-12-09 21:47:01,936) INFO - qlib.timer - [log.py:127] - Time cost: 0.073s | CSRankNorm Done\n",
      "[2910315:MainThread](2024-12-09 21:47:01,937) INFO - qlib.timer - [log.py:127] - Time cost: 4.013s | fit & process data Done\n",
      "[2910315:MainThread](2024-12-09 21:47:01,938) INFO - qlib.timer - [log.py:127] - Time cost: 16.998s | Init data Done\n"
     ]
    }
   ],
   "source": [
    "import qlib\n",
    "from qlib.constant import REG_CN\n",
    "data_uri = '~/.qlib/qlib_data/cn_data/'\n",
    "qlib.init(provider_uri=data_uri, region=REG_CN)\n",
    "from qlib.data.dataset.handler import DataHandlerLP\n",
    "\n",
    "# 使用\"配置\"进行实例化\n",
    "from qlib.utils import init_instance_by_config\n",
    "from qlib.contrib.data.handler import Alpha158\n",
    "from qlib.data.dataset import TSDatasetH\n",
    "from qlib.contrib.model.pytorch_alstm_ts import ALSTM\n",
    "\n",
    "# 配置数据\n",
    "train_period = (\"2017-01-01\", \"2018-12-31\")\n",
    "valid_period = (\"2019-01-01\", \"2019-12-31\")\n",
    "test_period = (\"2020-01-01\", \"2020-08-01\")\n",
    "\n",
    "dh = Alpha158(instruments='csi300', \n",
    "              start_time=train_period[0], \n",
    "              end_time=test_period[1],\n",
    "             fit_start_time = \"2018-01-01\",\n",
    "             fit_end_time = \"2019-12-31\",\n",
    "              infer_processors= [\n",
    "                        {\"class\": \"RobustZScoreNorm\", \"kwargs\": {\"fields_group\": \"feature\", \"clip_outlier\": \"true\"}},\n",
    "                        {\"class\": \"Fillna\", \"kwargs\": {\"fields_group\": \"feature\"}},\n",
    "                    ],\n",
    "            learn_processors= [\n",
    "                        \"DropnaLabel\",\n",
    "                        {\"class\": \"CSRankNorm\", \"kwargs\": {\"fields_group\": \"label\"}},  # CSRankNorm\n",
    "                    ],\n",
    "             )\n",
    "ds = TSDatasetH(handler=dh,\n",
    "                step_len=20, # 时间步数\n",
    "                segments={\"train\": train_period, \n",
    "                          \"valid\": valid_period, \n",
    "                          \"test\": test_period})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "#%%\n",
    "from qlib.data.dataset.handler import DataHandlerLP\n",
    "dl_train = ds.prepare(\"train\", col_set=[\"feature\", \"label\"], data_key=DataHandlerLP.DK_L)\n",
    "dl_valid = ds.prepare(\"valid\", col_set=[\"feature\", \"label\"], data_key=DataHandlerLP.DK_L)\n",
    "\n",
    "dl_train.config(fillna_type=\"ffill+bfill\")  # process nan brought by dataloader\n",
    "dl_valid.config(fillna_type=\"ffill+bfill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import math\n",
    "seed = 32\n",
    "np.random.seed(seed) \n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "dl_train, batch_size=5192, shuffle=True, num_workers=0, drop_last=True\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "dl_valid, batch_size=5192, shuffle=True, num_workers=0, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "train 1.102622, valid 1.509614\n",
      "Epoch 1\n",
      "train 1.057971, valid 1.298217\n",
      "Epoch 2\n",
      "train 1.040887, valid 1.503150\n",
      "Epoch 3\n",
      "train 1.034133, valid 1.189618\n",
      "Epoch 4\n",
      "train 1.029072, valid 1.844866\n",
      "Epoch 5\n",
      "train 1.026484, valid 1.320875\n",
      "Epoch 6\n",
      "train 1.021960, valid 1.675927\n",
      "Epoch 7\n",
      "train 1.021513, valid 1.189604\n",
      "Epoch 8\n",
      "train 1.019238, valid 1.327516\n",
      "Epoch 9\n",
      "train 1.018718, valid 1.249582\n",
      "Epoch 10\n",
      "train 1.016556, valid 1.472861\n",
      "Epoch 11\n",
      "train 1.016545, valid 1.298970\n",
      "Epoch 12\n",
      "train 1.015905, valid 2.430757\n",
      "Epoch 13\n",
      "train 1.014346, valid 2.085375\n",
      "Epoch 14\n",
      "train 1.013438, valid 1.280744\n",
      "Epoch 15\n",
      "train 1.014361, valid 2.355410\n",
      "Epoch 16\n",
      "train 1.013261, valid 1.471952\n",
      "Epoch 17\n",
      "train 1.012881, valid 1.240915\n",
      "Epoch 18\n",
      "train 1.011643, valid 1.209588\n",
      "Epoch 19\n",
      "train 1.012077, valid 1.180252\n",
      "Epoch 20\n",
      "train 1.011301, valid 1.197152\n",
      "Epoch 21\n",
      "train 1.011338, valid 2.470756\n",
      "Epoch 22\n",
      "train 1.010974, valid 1.409614\n",
      "Epoch 23\n",
      "train 1.010380, valid 2.218814\n",
      "Epoch 24\n",
      "train 1.010385, valid 1.995189\n",
      "Epoch 25\n",
      "train 1.010976, valid 1.707022\n",
      "Epoch 26\n",
      "train 1.010407, valid 1.173838\n",
      "Epoch 27\n",
      "train 1.009261, valid 2.801436\n",
      "Epoch 28\n",
      "train 1.008710, valid 1.308402\n",
      "Epoch 29\n",
      "train 1.009814, valid 1.300176\n",
      "Epoch 30\n",
      "train 1.008748, valid 1.217367\n",
      "Epoch 31\n",
      "train 1.008584, valid 1.345403\n",
      "Epoch 32\n",
      "train 1.008672, valid 1.206463\n",
      "Epoch 33\n",
      "train 1.008538, valid 1.153502\n",
      "Epoch 34\n",
      "train 1.008704, valid 1.263158\n",
      "Epoch 35\n",
      "train 1.007771, valid 1.180587\n",
      "Epoch 36\n",
      "train 1.008809, valid 3.304984\n",
      "Epoch 37\n",
      "train 1.007868, valid 2.142050\n",
      "Epoch 38\n",
      "train 1.006804, valid 1.484926\n",
      "Epoch 39\n",
      "train 1.007155, valid 1.222983\n",
      "Epoch 40\n",
      "train 1.007814, valid 1.162559\n",
      "Epoch 41\n",
      "train 1.007105, valid 1.131065\n",
      "Epoch 42\n",
      "train 1.007771, valid 1.551468\n",
      "Epoch 43\n",
      "train 1.007339, valid 1.617443\n",
      "Epoch 44\n",
      "train 1.006755, valid 1.242594\n",
      "Epoch 45\n",
      "train 1.006977, valid 1.254161\n",
      "Epoch 46\n",
      "train 1.005983, valid 1.208590\n",
      "Epoch 47\n",
      "train 1.005587, valid 1.382124\n",
      "Epoch 48\n",
      "train 1.006289, valid 1.206017\n",
      "Epoch 49\n",
      "train 1.005733, valid 1.196721\n",
      "Epoch 50\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory params does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m epoch)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# train_transformer(train_loader, epoch)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m\u001b[43mtrain_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m test_transformer(valid_loader)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain \u001b[39m\u001b[38;5;132;01m%.6f\u001b[39;00m\u001b[38;5;124m, valid \u001b[39m\u001b[38;5;132;01m%.6f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (train_loss, val_loss))\n",
      "File \u001b[0;32m~/proj/newModule/myTransformer/transformer.py:241\u001b[0m, in \u001b[0;36mtrain_transformer\u001b[0;34m(dataloader, epoch, model)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# print(f'batch_idx:{batch_idx}, loss: {loss.item()},feature: {feature.shape}')\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m50\u001b[39m):\n\u001b[0;32m--> 241\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparams/transformer_model_epoch\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(losses))\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/serialization.py:651\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    648\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 651\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    652\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[1;32m    653\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/serialization.py:525\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    524\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/serialization.py:496\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream))\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 496\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parent directory params does not exist."
     ]
    }
   ],
   "source": [
    "from transformer import train_transformer, test_transformer,TransformerModule\n",
    "import matplotlib.pyplot as plt\n",
    "n_epochs = 100\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "model = TransformerModule()\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"Epoch %d\" % epoch)\n",
    "    # train_transformer(train_loader, epoch)\n",
    "    train_loss =train_transformer(train_loader, epoch, model)\n",
    "    val_loss = test_transformer(valid_loader)\n",
    "    print(\"train %.6f, valid %.6f\" % (train_loss, val_loss))\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "\n",
    "# 绘制损失曲线\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newModuleEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
